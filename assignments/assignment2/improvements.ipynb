{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/cellverse/Desktop/cv/2011_10_03_drive_0034_sync/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finetune with new loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_pose_net =  True\n",
      "/home/cellverse/tools/miniconda3/envs/cs172/lib/python3.10/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "/home/cellverse/tools/miniconda3/envs/cs172/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Training model named:\n",
      "   back_projection\n",
      "Models and tensorboard events files are saved to:\n",
      "   /home/cellverse/Desktop/cv/log_dir\n",
      "Training is using:\n",
      "   cuda\n",
      "=======================================================\n",
      "size of training data = 8413\n",
      "=======================================================\n",
      "Using split:\n",
      "   my_split\n",
      "There are 8413 training items and 909 validation items\n",
      "\n",
      "  0%|                                                     | 0/2 [00:00<?, ?it/s]/home/cellverse/tools/miniconda3/envs/cs172/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/home/cellverse/tools/miniconda3/envs/cs172/lib/python3.10/site-packages/torch/nn/functional.py:4296: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "  0%|                                                     | 0/2 [00:18<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cellverse/Desktop/cv/ShanghaiTech-CS172/assignments/assignment2/./improvement/train.py\", line 18, in <module>\n",
      "    trainer.train()\n",
      "  File \"/home/cellverse/Desktop/cv/ShanghaiTech-CS172/assignments/assignment2/improvement/trainer.py\", line 205, in train\n",
      "    self.run_epoch()\n",
      "  File \"/home/cellverse/Desktop/cv/ShanghaiTech-CS172/assignments/assignment2/improvement/trainer.py\", line 231, in run_epoch\n",
      "    outputs, losses = self.process_batch(inputs)\n",
      "  File \"/home/cellverse/Desktop/cv/ShanghaiTech-CS172/assignments/assignment2/improvement/trainer.py\", line 296, in process_batch\n",
      "    losses = self.compute_losses(inputs, outputs)\n",
      "  File \"/home/cellverse/Desktop/cv/ShanghaiTech-CS172/assignments/assignment2/improvement/trainer.py\", line 578, in compute_losses\n",
      "    current_batch_size, current_height, current_width = predict_depth.shape\n",
      "ValueError: too many values to unpack (expected 3)\n"
     ]
    }
   ],
   "source": [
    "!python ./improvement/train.py --num_epochs 2 --split my_split --model_name back_projection --data_path /home/cellverse/Desktop/cv/2011_10_03_drive_0034_sync/ --png --log_dir /home/cellverse/Desktop/cv/log_dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python ./improvement/test_simple.py --image_path assets/occlusion.jpg --model_name mono+stereo_640x192 --model_path /home/cellverse/Desktop/cv/log_dir/back_projection/models/weights_0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs172",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
